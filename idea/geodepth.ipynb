{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea: Geo-Enabled Depth Estimation\n",
    "\n",
    "Overhead imagery can be used to understand the scale of the scene. If the geospatial context of an image is known (i.e., it is geocalibrated) we can infer an intermediate estimate of scale from the co-located overhead image and use it to augment depth estimation.\n",
    "\n",
    "Copyright Â© Scott Workman. 2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from nets.ops import generate_cutout\n",
    "from nets.geo import depth2voxel, voxel2pano\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = 16\n",
    "gsd = 0.7432\n",
    "\n",
    "data_dir = \"../holicity-overhead/\"\n",
    "\n",
    "df_images = pd.read_csv(\"{}images.txt\".format(data_dir), names=[\"ground\", \"lat\", \"lon\"])\n",
    "df_overhead = pd.read_csv(\"{}overhead/images_{}.txt\".format(data_dir, zoom),\n",
    "                          names=[\n",
    "                              \"overhead\", \"lat\", \"lon\", \"min_lon\",\n",
    "                              \"min_lat\", \"max_lon\", \"max_lat\"\n",
    "                          ])\n",
    "df = pd.concat((df_images, df_overhead), axis=1)\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a height map, generate a synthetic depth panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pano_size = [512, 1024]\n",
    "interesting_inds = [2000, 17000]\n",
    "\n",
    "for idx in interesting_inds:  \n",
    "  im_overhead = imageio.v2.imread(\"{}/overhead/{}\".format(data_dir, df[\"overhead\"].iloc[idx]))\n",
    "  im_height = np.load(\"{}/height/{}.npy\".format(data_dir, df[\"overhead\"].iloc[idx][:-4]))\n",
    "\n",
    "  orientations = torch.zeros(1).to(device)\n",
    "  t_height = torch.from_numpy(im_height).unsqueeze(0).unsqueeze(0)\n",
    "  voxel = depth2voxel(t_height.to(device), torch.tensor(gsd).to(device))\n",
    "  pano = voxel2pano(voxel, orientations, pano_size).detach().cpu().float().numpy().squeeze()\n",
    "  \n",
    "  # handle no data regions\n",
    "  im_height[im_height == -9999] = np.nan\n",
    "  pano[pano > (256 * gsd * .95)] = np.nan\n",
    "  \n",
    "  plt.figure(figsize=(15,15))\n",
    "  plt.subplot(131)\n",
    "  plt.imshow(im_overhead)\n",
    "  plt.axis('off')\n",
    "  plt.subplot(132)\n",
    "  plt.imshow(im_height, vmin=np.nanquantile(im_height, [.1]), vmax=np.nanquantile(im_height, [.9]))\n",
    "  plt.axis('off')\n",
    "  plt.subplot(133)\n",
    "  plt.imshow(pano, vmax=50)\n",
    "  plt.axis('off')\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given a geocalibrated image, extract the corresponding depth cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pano_size = [512, 1024]\n",
    "interesting_inds = [2000, 17000]\n",
    "\n",
    "for idx in interesting_inds: \n",
    "  im =  imageio.v2.imread(\"{}image/{}_imag.jpg\".format(data_dir, df[\"ground\"].iloc[idx]))\n",
    "  depth = np.load(\"{}depth/{}_dpth.npz\".format(data_dir, df[\"ground\"].iloc[idx]))[\"depth\"].squeeze()\n",
    "  geo = np.load(\"{}geo/{}_camr.npz\".format(data_dir, df[\"ground\"].iloc[idx]))\n",
    "  im_overhead = imageio.v2.imread(\"{}/overhead/{}\".format(data_dir, df[\"overhead\"].iloc[idx]))\n",
    "  im_height = np.load(\"{}/height/{}.npy\".format(data_dir, df[\"overhead\"].iloc[idx][:-4]))\n",
    "\n",
    "  yaw = torch.tensor(geo[\"yaw\"])\n",
    "  pitch = torch.tensor(geo[\"pitch\"])\n",
    "\n",
    "  orientations = torch.zeros(1).to(device)\n",
    "  t_height = torch.from_numpy(im_height).unsqueeze(0).unsqueeze(0)\n",
    "  voxel = depth2voxel(t_height.to(device), torch.tensor(gsd).to(device))\n",
    "  pano = voxel2pano(voxel, orientations, pano_size).squeeze(0)\n",
    "  cutout = generate_cutout(pano, yaw=yaw, pitch=pitch).detach().cpu().numpy().squeeze()\n",
    "\n",
    "  pano = pano.detach().cpu().numpy().squeeze()\n",
    "  \n",
    "  # handle no data regions\n",
    "  depth[depth == 0] = np.nan\n",
    "  pano[pano > (256 * gsd * .95)] = np.nan\n",
    "  cutout[cutout > (256 * gsd * .95)] = np.nan\n",
    "  \n",
    "  plt.figure(figsize=(15,15))\n",
    "  plt.subplot(141)\n",
    "  plt.imshow(pano, vmax=50)  \n",
    "  plt.axis(\"off\")\n",
    "  plt.subplot(142)\n",
    "  plt.imshow(im)\n",
    "  plt.axis(\"off\")\n",
    "  plt.subplot(143)\n",
    "  plt.imshow(depth, vmin=0, vmax=50)\n",
    "  plt.axis(\"off\")\n",
    "  plt.subplot(144)\n",
    "  plt.imshow(cutout, vmin=0, vmax=50)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geodepth]",
   "language": "python",
   "name": "conda-env-geodepth-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
